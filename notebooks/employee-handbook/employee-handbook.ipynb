{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneriCorp Employee Handbook\n",
    "This notebook demonstrates how I simulated the documents representing GeneriCorp's employee handbook. I chose NOT to use ChatGPT directly since it would have been too tedious to generate all these by hand! As such, I'll demonstrate for you how we can use the OpenAI API to generate these documents in an automated, efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the chat model\n",
    "chat_model = ChatOpenAI(api_key = os.environ['OPENAI_API_KEY'],\n",
    "                        model = 'gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the company history from file\n",
    "with open('../../genericorp/about-gc/company-history.md', 'r', encoding = 'utf-8') as file:\n",
    "    company_history = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Handbook Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the topic generation prompt\n",
    "TOPIC_GENERATION_PROMPT = '''Imagine a fictional company called GeneriCorp. Their company history is as follows:\n",
    "\n",
    "{company_history}\n",
    "\n",
    "Please generate a list of topics they may be found within the employee handbook. Please output them in a Python comma-separated list format. Do not provide any additional text aside from the Python list.'''\n",
    "\n",
    "# Instantiating the output parser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Setting up the chat prompt template\n",
    "topic_generation_prompt_template = PromptTemplate(\n",
    "    template = TOPIC_GENERATION_PROMPT + '\\n{format_instructions}',\n",
    "    input_variables = ['company_history'],\n",
    "    partial_variables = {'format_instructions': output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Creating the topic generation chain\n",
    "topic_generation_chain = topic_generation_prompt_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 21\n",
      "Topics: ['company_culture', 'code_of_conduct', 'benefits_and_compensation', 'employee_wellness_programs', 'diversity_and_inclusion', 'harassment_and_discrimination_policies', 'workplace_safety', 'remote_work_policies', 'performance_reviews', 'training_and_development', 'confidentiality_agreements', 'intellectual_property', 'employee_resources', 'leave_policies', 'travel_policies', 'communication_guidelines', 'ethics_and_compliance', 'work-life_balance', 'grievance_procedures', 'team_building_activities', 'recognition_programs']\n"
     ]
    }
   ],
   "source": [
    "# Setting the name of a topics cache file\n",
    "TOPICS_CACHE_FILE = 'handbook_topics.json'\n",
    "\n",
    "# Checking if cached topics exist\n",
    "if os.path.exists(TOPICS_CACHE_FILE):\n",
    "    \n",
    "    # Loading topics from cache\n",
    "    with open(TOPICS_CACHE_FILE, 'r') as f:\n",
    "        handbook_topics = json.load(f)\n",
    "        \n",
    "else:\n",
    "\n",
    "    # Generating topics using the AI model\n",
    "    handbook_topics = topic_generation_chain.invoke({\"company_history\": company_history})\n",
    "    \n",
    "    # Caching the results\n",
    "    with open(TOPICS_CACHE_FILE, 'w') as f:\n",
    "        json.dump(handbook_topics, f)\n",
    "\n",
    "# Replacing spaces with underscores in handbook topics\n",
    "handbook_topics = [topic.replace(' ', '_') for topic in handbook_topics]\n",
    "\n",
    "print(f\"Number of topics: {len(handbook_topics)}\")\n",
    "print(\"Topics:\", handbook_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Handbook Pages from the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the handbook page generation prompt\n",
    "HANDBOOK_PAGE_GENERATION_PROMPT = '''Imagine a fictional company called GeneriCorp. Their company history is as follows:\n",
    "{company_history}\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
